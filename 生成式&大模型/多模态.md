# 多模态学习综述
## 一、定义
多模态机器学习（MultiModal Machine Learning，MMML）。

**<font style="color:rgb(25, 27, 31);">模态是指一些表达或感知事物的方式，每一种信息的来源或者形式，都可以称为一种模态</font>**<font style="color:rgb(25, 27, 31);">。</font>**<font style="color:rgb(25, 27, 31);">相较于图像、语音、文本等多媒体(Multi-media)数据划分形式，“模态”是一个更为细粒度的概念，同一媒介下可存在不同的模态。</font>**<font style="color:rgb(25, 27, 31);"> 比如我们可以把两种不同的语言当做是两种模态，甚至在两种不同情况下采集到的数据集，亦可认为是两种模态。</font>

<font style="color:rgb(25, 27, 31);">多模态研究主要包括</font>**<font style="color:rgb(25, 27, 31);">“3V”</font>**<font style="color:rgb(25, 27, 31);">：Verbal（文本）、Vocal（语音）、Visual（视觉）。</font>

![](https://cdn.nlark.com/yuque/0/2025/png/49665485/1758510028827-44f2cffe-7c05-4f2a-a1ff-603e68b917c5.png)



## <font style="color:rgb(25, 27, 31);">二、典型任务</font>
### <font style="color:rgb(25, 27, 31);">2.1 </font>跨模块预训练
+ <font style="color:rgb(25, 27, 31);">图像/视频与语言预训练。</font>
+ <font style="color:rgb(25, 27, 31);">跨任务预训练</font>

### <font style="color:rgb(25, 27, 31);">32.2 Language-Audio</font>
+ <font style="color:rgb(25, 27, 31);">Text-to-Speech Synthesis: 给定文本，生成一段对应的声音。</font>
+ <font style="color:rgb(25, 27, 31);">Audio Captioning：给定一段语音，生成一句话总结并描述主要内容。(不是语音识别)</font>

### <font style="color:rgb(25, 27, 31);">2.3 Vision-Audio</font>
+ <font style="color:rgb(25, 27, 31);">Audio-Visual Speech Recognition(视听语音识别)：给定某人的视频及语音进行语音识别。</font>
+ <font style="color:rgb(25, 27, 31);">Video Sound Separation(视频声源分离)：给定视频和声音信号(包含多个声源)，进行声源定位与分离。</font>
+ <font style="color:rgb(25, 27, 31);">Image Generation from Audio: 给定声音，生成与其相关的图像。</font>
+ <font style="color:rgb(25, 27, 31);">Speech-conditioned Face generation：给定一段话，生成说话人的视频。</font>
+ <font style="color:rgb(25, 27, 31);">Audio-Driven 3D Facial Animation：给定一段话与3D人脸模版，生成说话的人脸3D动画。</font>

### <font style="color:rgb(25, 27, 31);">2.4 Vision-Language</font>
+ <font style="color:rgb(25, 27, 31);">Image/Video-Text Retrieval (图(视频)文检索): 图像/视频<-->文本的相互检索。</font>
+ <font style="color:rgb(25, 27, 31);">Image/Video Captioning(图像/视频描述)：给定一个图像/视频，生成文本描述其主要内容。</font>
+ <font style="color:rgb(25, 27, 31);">Visual Question Answering(视觉问答)：给定一个图像/视频与一个问题，预测答案。</font>
+ <font style="color:rgb(25, 27, 31);">Image/Video Generation from Text：给定文本，生成相应的图像或视频。</font>
+ <font style="color:rgb(25, 27, 31);">Multimodal Machine Translation：给定一种语言的文本与该文本对应的图像，翻译为另外一种语言。</font>
+ <font style="color:rgb(25, 27, 31);">Vision-and-Language Navigation(视觉-语言导航)： 给定自然语言进行指导，使得智能体根据视觉传感器导航到特定的目标。</font>
+ <font style="color:rgb(25, 27, 31);">Multimodal Dialog(多模态对话)： 给定图像，历史对话，以及与图像相关的问题，预测该问题的回答。</font>

### <font style="color:rgb(25, 27, 31);">2.5 定位相关的任务</font>
+ <font style="color:rgb(25, 27, 31);">Visual Grounding：给定一个图像与一段文本，定位到文本所描述的物体。</font>
+ <font style="color:rgb(25, 27, 31);">Temporal Language Localization: 给定一个视频即一段文本，定位到文本所描述的动作(预测起止时间)。</font>
+ <font style="color:rgb(25, 27, 31);">Video Summarization from text query：给定一段话(query)与一个视频，根据这段话的内容进行视频摘要，预测视频关键帧(或关键片段)组合为一个短的摘要视频。</font>
+ <font style="color:rgb(25, 27, 31);">Video Segmentation from Natural Language Query: 给定一段话(query)与一个视频，分割得到query所指示的物体。</font>
+ <font style="color:rgb(25, 27, 31);">Video-Language Inference: 给定视频(包括视频的一些字幕信息)，还有一段文本假设(hypothesis)，判断二者是否存在语义蕴含(二分类)，即判断视频内容是否包含这段文本的语义。</font>
+ <font style="color:rgb(25, 27, 31);">Object Tracking from Natural Language Query: 给定一段视频和一些文本，追踪视频中文本所描述的对象。</font>
+ <font style="color:rgb(25, 27, 31);">Language-guided Image/Video Editing: 一句话自动修图。给定一段指令(文本)，自动进行图像/视频的编辑。</font>

## 三、总结
多模态偏向于识别的功能，通过将文本、图片、语音等模态的信息，统一到一个向量空间中，从而实现模态之间的转换和识别。

![](https://cdn.nlark.com/yuque/0/2025/png/49665485/1758527282417-a00b747e-fddf-4706-93fb-1d1d7057a882.png)

通俗来说，就是将用户提供的所有信息全部转化为计算机能够看的形式，如此来实现信息的交互。

因此对于视频编解码方面的应用：

1. 场景识别，通过识别场景来对重要区域分配更多的比特
2. 跨模块注意力，利用语义或文本的情感信息，判断视频中的哪些时刻需要更清晰的画面
3. 语义压缩，将视频信息转化为文本信息，传输到解码端后，通过文本信息恢复图像信息
4. 短视频平台，利用NLP提取视频主题标签，引导关键帧选择和码率分配

