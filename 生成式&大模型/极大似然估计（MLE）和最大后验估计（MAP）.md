# 极大似然估计（MLE）和最大后验估计（MAP）

前言：学习深度学习，尤其学习生成式模型会用到大量关于概率与统计的概念，尤其关于最大后验概率的知识。这里我来写一下我关于这一部分的理解。如果有什么不同的看法欢迎和我讨论。

## 0. 博客

这里有几篇不错的博客我放这里：

[(40 封私信 / 80 条消息) 聊一聊机器学习的MLE和MAP：最大似然估计和最大后验估计 - 知乎](https://zhuanlan.zhihu.com/p/32480810)

[(40 封私信 / 80 条消息) 机器学习方法—统计：MLE与MAP - 知乎](https://zhuanlan.zhihu.com/p/345024301)

（这里只放了2篇，后面看到好的了再贴，(#\^.^#)）

## 1. 什么是先验，什么是后验？

这个具体要看你怎么看待问题，同一个变量，当你看的角度不同，他可以是输入也可以是输出。所以讨论这个问题我们应该明确什么是输入什么是输出。

对于这个问题我们可以这样理解，我们想估计某一变量$X$，但我们没办法直接求解，因此，我们设计了一个实验$X\to Y$，可以获得$Y$，然后我们根据$Y$来估计$X$

为了直观理解，我用下面这个表示：
$$
I \to 系统 \to O
$$
先验：$P(I)$，意思是我们在实验前对这个变量有的经验；

后验：$P(I|O)$，意思我们知道实验结果后，对我们待估计量的概率

ps：有些地方先验也写成$P(O|I)$（这个说法不知道对不对，反正建议按上面两个来），这个其实是我们设计的实验（系统），我习惯叫他条件概率，或者似然概率。

## 2. 最大似然估计（Maximum Likelihood Estimation, MLE）

**最大似然，概率最大我们就认为他一定发生，那反过来如果它发生我们就认为他概率最大。**

比如，我们要估计$X$，知道$X\to Y$，获得的$Y$，那我们可以构建似然函数$L(X) = P(Y|X)$求他的极大值点就可以。

这样不理解？咱换个眼熟的例子：求某个分布的待确定的参数$\theta$，已知从该分分布中采样的数据$\{x_i\}$， 我们可以构建似然函数$L(\theta) = P(X|\theta)$

![1](.\Pic\1.png)

ps：i.i.d是独立同分布

## 3. 最大后验估计（Maximum A Posteriori, MAP）

直接上别人的解释：

![2](./pic/2.png)

这里我多说一个，后验概率$P(\theta|X)$(ps:你也可以看成$P(I|O)$)，为什么直接算不了（这是我的看法，如果有其他见解欢迎讨论）：

​	比如我们求分布参数这个例子来看，$P(\theta|X)$，这个不就是我们的题干吗？这不是废话，我要是知道怎么算，还需要算你。

> ​	求某个分布的待确定的参数$\theta$，已知从该分分布中采样的数据$\{x_i\}$	

​	反之，似然概率$P(X|\theta)$，我们可以直接从分布中采样算出来。

至于先验概率，更像人们用自己的经验对其进行约束。聪明的你可能已经发现了，极大似然估计和最大后验估计就差了一项，就是$-log(P(\theta))$，这不就是正则项嘛，(对上了，对上了，这一切都对上了\_(:з」∠)_)。至于这些，博客都有深入讲解，我就不多说了。



